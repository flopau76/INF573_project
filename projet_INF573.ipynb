{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EHzuWbHtlWh_"
      },
      "source": [
        "# rappel structure des données:  \n",
        "Grey images are stored in memory as 2D arrays, color images as a 3D arrays\n",
        "\n",
        "io.imread returns a np.array of shape (hauteur, largeur, 3) or (hauteur, largeur)\n",
        "* image [ 0 , 0 ] : upper left corner\n",
        "* image [ 0 , n ] : upper right corner\n",
        "* image [ n , 0 ] : lower left corner\n",
        "* image [ : , 0:n/2 ] : left half of picture\n",
        "\n",
        "size of video picture: 1080, 1920\n",
        "\n",
        "doc: https://docs.opencv.org/master, mostly in the features2D and calib3d modules"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l-SwRbvTGRnu"
      },
      "outputs": [],
      "source": [
        "%matplotlib widget\n",
        "%matplotlib inline\n",
        "\n",
        "import numpy as np\n",
        "import math\n",
        "import cv2 as cv2 # opencv computer vision library\n",
        "from skimage import io # for io.imread\n",
        "from matplotlib import pyplot as plt # ploting\n",
        "from matplotlib import colors # ploting\n",
        "\n",
        "import mediapipe as mp  # human pose detection\n",
        "\n",
        "import ast # string representation of list to list using ast.literal_eval()\n",
        "\n",
        "# interactive notebook widgets\n",
        "import ipywidgets as widgets\n",
        "from ipywidgets import interact, interact_manual"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "root_directory = 'data/'\n",
        "\n",
        "plan_large_1 = io.imread(root_directory + '01.18.42.183_front.png')\n",
        "plan_cote_1 =  io.imread(root_directory + '01.18.47.450_side1.png')\n",
        "plan_cote_2 =  io.imread(root_directory + '01.18.52.000_side2.png')\n",
        "\n",
        "travel_front = io.imread_collection (root_directory + 'travel_front/*')\n",
        "\n",
        "# autre\n",
        "plan_face_autre = io.imread(root_directory + 'other/front.jpg')\n",
        "plan_cote_autre = io.imread(root_directory + 'other/side.jpg')\n",
        "plan_shema = io.imread(root_directory + 'other/shematic.jpg')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 277
        },
        "id": "xbsGIF2iKuk4",
        "outputId": "70ed010c-3894-40f1-8d43-9ebe2cb4d247"
      },
      "outputs": [],
      "source": [
        "def imshow(images, titles=\"123456789\", callback = None, nrows = 0, ncols=0, figsize = (15,20)):\n",
        "    \"\"\"Plot a multiple images with titles.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    images : image list\n",
        "    titles : title list\n",
        "    ncols : number of columns of subplots wanted in the display\n",
        "    nrows : number of rows of subplots wanted in the figure\n",
        "    \"\"\"\n",
        "\n",
        "    if ncols == 0 and nrows == 0:\n",
        "        ncols = len(images)\n",
        "        nrows = 1\n",
        "    if ncols == 0:\n",
        "        ncols = len(images) // nrows\n",
        "    if nrows == 0:\n",
        "        nrows = len(images) // ncols\n",
        "\n",
        "    fig, axeslist = plt.subplots(ncols=ncols, nrows=nrows, squeeze=False, figsize = figsize)\n",
        "    for i, image in enumerate(images):\n",
        "        axeslist.ravel()[i].imshow(image, cmap=plt.gray(), vmin=0, vmax=255)\n",
        "        axeslist.ravel()[i].set_title(titles[i])\n",
        "        axeslist.ravel()[i].set_axis_off()\n",
        "    plt.tight_layout() # optional\n",
        "\n",
        "    if callback is not None:\n",
        "        def onclick(event):\n",
        "            [i],[j] = np.where(axeslist == event.inaxes)\n",
        "            callback(axeslist, [i,j], [event.xdata, event.ydata])\n",
        "\n",
        "        # Create an hard reference to the callback not to be cleared by the garbage collector\n",
        "        ka = fig.canvas.mpl_connect('button_press_event', onclick)\n",
        "    return axeslist\n",
        "\n",
        "print (len(travel_front))\n",
        "axeslist = imshow (travel_front)\n",
        "print(type(axeslist))\n",
        "print(axeslist.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "vTcu39WEK2WP",
        "outputId": "cdd6ad98-519e-4eb3-a358-118c0912b87f"
      },
      "outputs": [],
      "source": [
        "def extract_key_points(img1, img2):\n",
        "    akaze = cv2.AKAZE_create()\n",
        "    kp1, des1 = akaze.detectAndCompute (img1,None)\n",
        "    kp2, des2 = akaze.detectAndCompute (img2,None)\n",
        "    return kp1, des1, kp2, des2\n",
        "\n",
        "def showKeyPoints(img1, kp1, img2, kp2):\n",
        "    img_1 = cv2.drawKeypoints( img1, kp1, None) \n",
        "    img_2 = cv2.drawKeypoints( img2, kp2, None) \n",
        "    imshow([img_1, img_2],[\"left\", \"right\"])\n",
        "\n",
        "def match_key_points(kp1, des1, kp2, des2):\n",
        "    bf = cv2.BFMatcher()\n",
        "    # Match descriptors.\n",
        "    matches = bf.match(des1,des2)\n",
        "    # Sort them in the order of their distance.\n",
        "    return sorted(matches, key = lambda x:x.distance)\n",
        "\n",
        "def showMatches(img1, kp1, img2, kp2, matches, name):\n",
        "    img = cv2.drawMatches(img1,kp1,img2,kp2,matches,None,flags=cv2.DrawMatchesFlags_NOT_DRAW_SINGLE_POINTS)\n",
        "    imshow([img],[name])\n",
        "\n",
        "def findHomography(matches, keypoint1, keypoint2):\n",
        "    src_pts = np.array([keypoint1[matches[m].queryIdx].pt for m in range(len(matches))])\n",
        "    dst_pts = np.array([keypoint2[match.trainIdx].pt for match in matches])\n",
        "    H, mask = cv2.findHomography(src_pts, dst_pts, cv2.RANSAC,5.0)\n",
        "    inliers = [matches[m] for m in range(len(mask)) if mask[m]==1]\n",
        "    return H,inliers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "lqirxjdzNTUl",
        "outputId": "ea9b8327-0b5e-46e1-a420-928a7f0c2531"
      },
      "outputs": [],
      "source": [
        "def panorama_pipeline (images,final_size, location=\"ul\"):\n",
        "    x,y, = final_size\n",
        "    nb_img = len(images)\n",
        "    img_pano = images[0]\n",
        "\n",
        "    y1,x1, _ = images[0].shape\n",
        "    H = np.array([[1.,0.,0.],[0.,1.,0.],[0.,0.,1.]])\n",
        "    # location = where to place first image\n",
        "        # first letter = up/middle/bottom\n",
        "        # second letter = left/middle/right\n",
        "    if location[1]=='m':\n",
        "        H[0][2] = (x1-x)/2\n",
        "    if location[1]=='r':\n",
        "        H[0][2] = x1-x\n",
        "    if location[0]=='m':\n",
        "        H[1][2] = (y1-y)/2\n",
        "    if location[0]=='b':\n",
        "        H[1][2] = y1-y\n",
        "\n",
        "    img_pano =  255*np.ones((y, x, 3),dtype=np.uint8)\n",
        "    img_pano = cv2.warpPerspective(images[0], H, final_size, img_pano, borderMode=cv2.BORDER_TRANSPARENT, flags=cv2.WARP_INVERSE_MAP)\n",
        "\n",
        "    for i in range (1,nb_img):\n",
        "        img1= images[i-1]\n",
        "        img2= images[i]\n",
        "        kp_1, des_1, kp_2, des_2 = extract_key_points(img1, img2)\n",
        "        matches_pipeline = match_key_points(kp_1, des_1, kp_2, des_2)\n",
        "        H2, inliers = findHomography(matches_pipeline, kp_1, kp_2)\n",
        "        H=np.matmul(H2, H)\n",
        "        img_pano = cv2.warpPerspective(img2, H, final_size, img_pano, borderMode=cv2.BORDER_TRANSPARENT, flags=cv2.INTER_LINEAR + cv2.WARP_INVERSE_MAP)\n",
        "    return img_pano\n",
        "\n",
        "pano = panorama_pipeline(travel_front,(3000,4000), \"bm\")\n",
        "imshow([pano], [\"panorama\"] )\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Extracting edges by hand (clicking points)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pcjL5bZDk4Na"
      },
      "outputs": [],
      "source": [
        "def draw_point(axe, point, color):\n",
        "    # draw the clicked point\n",
        "    axe.scatter([point[0]], [point[1]], color=[color], s=400, marker='+')\n",
        "\n",
        "def onclick_get_coord(axeslist, ij, p):\n",
        "    i = ij[0] # row == 0\n",
        "    j = ij[1] # column == 0 or 1 for left or right image\n",
        "    color = np.random.rand(3) # take a random color \n",
        "    draw_point(axeslist[i, j], p, color)\n",
        "    print(f\"{p[0]}  {p[1]}\")\n",
        "\n",
        "# axeslist = imshow( [plan_cote_1, plan_large_1], ['côté', 'face'], onclick_get_coord)\n",
        "axeslist = imshow( [plan_face_autre], ['autre'], onclick_get_coord)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\"\"\"f = open(\"data/front_other_face.txt\", \"r\")\n",
        "L_front_other = []\n",
        "for line in f:\n",
        "  coords = ast.literal_eval(line)\n",
        "  L_front_other.append(coords)\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "color = np.random.rand((3))\n",
        "counter = 0\n",
        "\n",
        "\n",
        "def onclick_get_all_coord(axeslist, ij, p):\n",
        "    global color, counter\n",
        "    i = ij[0] # row == 0\n",
        "    j = ij[1] # column == 0 or 1 for left or right image\n",
        "    # take a random color\n",
        "    if i==0:\n",
        "        color = np.random.rand((3))\n",
        "    draw_point(axeslist[i, j], p, color)\n",
        "    print(f\"{counter}  {i}  {p[0]}  {p[1]}\")\n",
        "    if i==axeslist.size-1:\n",
        "        counter += 1\n",
        "\n",
        "# axeslist = imshow( [plan_cote_1, plan_large_1], ['côté', 'face'], onclick_get_coord)\n",
        "axeslist = imshow( [plan_face_autre, plan_cote_autre], ['face', 'côté'], onclick_get_all_coord, ncols=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "color = np.random.rand((3))\n",
        "counter = 0\n",
        "\n",
        "def onclick_show_place(axeslist, ij, p):\n",
        "    global color, counter, L_front_other\n",
        "    i = ij[0] # row == 0\n",
        "    j = ij[1] # column == 0 or 1 for left or right image\n",
        "    # take a random color\n",
        "    if i==0:\n",
        "        color = np.random.rand((3))\n",
        "        draw_point(axeslist[i, j], L_front_other[counter], color)\n",
        "        counter += 1\n",
        "    else:\n",
        "        draw_point(axeslist[i, j], p, color)\n",
        "        print(f\"{counter}:   {p[0]}  {p[1]}\")\n",
        "\n",
        "# axeslist = imshow( [plan_cote_1, plan_large_1], ['côté', 'face'], onclick_get_coord)\n",
        "axeslist = imshow( [plan_face_autre, plan_cote_autre], ['face', 'côté', 'shema'], onclick_show_place, ncols=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### trying a line detector to detect facettes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "dst = cv2.Canny(plan_cote_1, 0, 50, None, 3)\n",
        "\n",
        "# Copy edges to the images that will display the results in BGR\n",
        "cdst = cv2.cvtColor(dst, cv2.COLOR_GRAY2BGR)\n",
        "cdstP = np.copy(cdst)\n",
        "\n",
        "lines = cv2.HoughLines(dst, 1, np.pi / 180, 150, None, 0, 0)\n",
        "\n",
        "if lines is not None:\n",
        "    for i in range(0, len(lines)):\n",
        "        rho = lines[i][0][0]\n",
        "        theta = lines[i][0][1]\n",
        "        a = math.cos(theta)\n",
        "        b = math.sin(theta)\n",
        "        x0 = a * rho\n",
        "        y0 = b * rho\n",
        "        pt1 = (int(x0 + 1000*(-b)), int(y0 + 1000*(a)))\n",
        "        pt2 = (int(x0 - 1000*(-b)), int(y0 - 1000*(a)))\n",
        "        cv2.line(cdst, pt1, pt2, (0,0,255), 3, cv2.LINE_AA)\n",
        "\n",
        "\n",
        "linesP = cv2.HoughLinesP(dst, 1, np.pi / 180, 50, None, 50, 10)\n",
        "\n",
        "if linesP is not None:\n",
        "    for i in range(0, len(linesP)):\n",
        "        l = linesP[i][0]\n",
        "        cv2.line(cdstP, (l[0], l[1]), (l[2], l[3]), (0,0,255), 3, cv2.LINE_AA)\n",
        "\n",
        "imshow([plan_cote_1, dst, cdst, cdstP], [\"source\", \"canny\", \"standard detection\", \"probabilistic detection\"], nrows=2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### trying color blob detector to identify facettes\n",
        "does not work because blobs to  big ?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Set up the detector with default parameters.\n",
        "detector = cv2.SimpleBlobDetector_create()\n",
        " # Detect blobs.\n",
        "keypoints = detector.detect(plan_cote_1)\n",
        "img_with_kp = cv2.drawKeypoints( plan_cote_1, keypoints, None)\n",
        "imshow([img_with_kp], [\"image with kpts\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# detecting human pose with media pipe"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### time stamp of climbers:\n",
        "1h24: first man"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# initialize Pose estimator\n",
        "mp_drawing = mp.solutions.drawing_utils\n",
        "mp_pose = mp.solutions.pose\n",
        "\n",
        "pose = mp_pose.Pose(\n",
        "    min_detection_confidence=0.5,\n",
        "    min_tracking_confidence=0.5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# create capture object\n",
        "cap = cv2.VideoCapture('data/video.mp4')\n",
        "\n",
        "print(type(cap))\n",
        "\n",
        "while cap.isOpened():\n",
        "    print(\"ok\")\n",
        "    # read frame from capture object\n",
        "    _, frame = cap.read()\n",
        "\n",
        "    # convert the frame to RGB format\n",
        "    rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
        "    \n",
        "    # process the RGB frame to get the result\n",
        "    results = pose.process(rgb_frame)\n",
        "    print(results.pose_landmarks)\n",
        "    # draw detected skeleton on the frame\n",
        "    mp_drawing.draw_landmarks(\n",
        "    \tframe, results.pose_landmarks, mp_pose.POSE_CONNECTIONS)\n",
        "\n",
        "    # show the final output\n",
        "    cv2.imshow('Output', frame)\n",
        "\n",
        "    if cv2.waitKey(1) == ord('q'):\n",
        "            break\n",
        "cap.release()\n",
        "cv2.destroyAllWindows()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
